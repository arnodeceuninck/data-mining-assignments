{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import data\n",
    "This is the code from the assignment to load the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "[{5614842, 5766379},\n {5861791, 5894239},\n {5830270, 5830275},\n {5635117, 5751383, 5809910},\n {5767496, 5767497, 5891498}]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "baskets = dataset.groupby(\"user_id\").product_id.apply(set).tolist()\n",
    "baskets[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Association rule mining algorithm\n",
    "> Implement an association rule mining algorithm, or use an existing online implementation.\n",
    "Show that you understand the method by describing its function (without using code) in your\n",
    "report. Make sure you are able to get the confidence and support of any found association\n",
    "rules.\n",
    "\n",
    "> Run the association rule mining algorithm on the given dataset. At this point, use only the\n",
    "user id and product id columns. What are the top 10 association rules in terms of support\n",
    "your method finds? Also include the confidence of these rules. What can you say about the\n",
    "number of items in these rules?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 1\n",
    "I started with the apyori implementation, but this also allowed empty baskets, which causes errors in the inspect function. You can just skip to my own implementation, which you can find under the \"Method 4\" subtitle.\n",
    "Using code from [this article](https://www.section.io/engineering-education/apriori-algorithm-in-python/), with the apriori algorithm from [apyori](https://pypi.org/project/apyori/)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "# support: measures the number of times a particular item or combination of items occur in a dataset\n",
    "# confidence: measures how likely the customer is to consume item2 given they have consumed item1\n",
    "# lift: a metric that determines the strength of association between the best rules, confidence/support\n",
    "# TODO: define own min_upport, min_confidence and min_lift\n",
    "rule = apriori(transactions=baskets, min_support=0.003, min_confidence=0.2, min_lift=3, min_length=2, max_length=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "   Left_Hand_Side  Right_Hand_Side   Support  Confidence        Lift\n0         5677043          5697463  0.004187    0.329341   57.687425\n2         5809912          5809910  0.003730    0.583333   25.459302\n3         5814516          5814517  0.003730    0.875000  201.664474\n1         5809911          5809910  0.003578    0.746032   32.560196",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Left_Hand_Side</th>\n      <th>Right_Hand_Side</th>\n      <th>Support</th>\n      <th>Confidence</th>\n      <th>Lift</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5677043</td>\n      <td>5697463</td>\n      <td>0.004187</td>\n      <td>0.329341</td>\n      <td>57.687425</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5809912</td>\n      <td>5809910</td>\n      <td>0.003730</td>\n      <td>0.583333</td>\n      <td>25.459302</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5814516</td>\n      <td>5814517</td>\n      <td>0.003730</td>\n      <td>0.875000</td>\n      <td>201.664474</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5809911</td>\n      <td>5809910</td>\n      <td>0.003578</td>\n      <td>0.746032</td>\n      <td>32.560196</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list(rule)\n",
    "\n",
    "# putting output into a pandas dataframe\n",
    "def inspect(output):\n",
    "    for result in output:\n",
    "        try:\n",
    "            tuple(result[2][0][0])[0]\n",
    "        except Exception as e:\n",
    "            print(result)\n",
    "            raise e\n",
    "    lhs = [tuple(result[2][0][0])[0] for result in output]\n",
    "    rhs = [tuple(result[2][0][1])[0] for result in output]\n",
    "    support = [result[1] for result in output]\n",
    "    confidence = [result[2][0][2] for result in output]\n",
    "    lift = [result[2][0][3] for result in output]\n",
    "    return list(zip(lhs, rhs, support, confidence, lift))\n",
    "\n",
    "output_DataFrame = pd.DataFrame(inspect(results),\n",
    "                                columns=['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
    "\n",
    "output_DataFrame.nlargest(n=10, columns='Support')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 2\n",
    "Using code from [this site](https://towardsdatascience.com/apriori-association-rule-mining-explanation-and-python-implementation-290b42afdfc6), which uses the [apriori_python library](https://pypi.org/project/apriori-python/). This method is also very slow, so trying eclat insted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5614842, 5766379], [5894239, 5861791], [5830275, 5830270], [5635117, 5809910, 5751383], [5767496, 5767497, 5891498]]\n",
      "{1: {frozenset({5809910}), frozenset({5649236}), frozenset({5677043}), frozenset({5790689})}}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from apriori_python import apriori\n",
    "freqItemSet, rules = apriori(baskets, minSup=0.01, minConf=0.001)\n",
    "print(freqItemSet)\n",
    "print(rules)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 3\n",
    "Let's try running eclat on it. To do this, I'll use code from [this site](https://towardsdatascience.com/the-eclat-algorithm-8ae3276d2d17), which makes use of [pyECLAT](https://pypi.org/project/pyECLAT/). This method also gives an error.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         0          1          2   3   4   5   6   7   8   9\n0  5614842  5766379.0        NaN NaN NaN NaN NaN NaN NaN NaN\n1  5894239  5861791.0        NaN NaN NaN NaN NaN NaN NaN NaN\n2  5830275  5830270.0        NaN NaN NaN NaN NaN NaN NaN NaN\n3  5635117  5809910.0  5751383.0 NaN NaN NaN NaN NaN NaN NaN\n4  5767496  5767497.0  5891498.0 NaN NaN NaN NaN NaN NaN NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5614842</td>\n      <td>5766379.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5894239</td>\n      <td>5861791.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5830275</td>\n      <td>5830270.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5635117</td>\n      <td>5809910.0</td>\n      <td>5751383.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5767496</td>\n      <td>5767497.0</td>\n      <td>5891498.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(baskets)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# we are looking for itemSETS\n",
    "# we do not want to have any individual products returned\n",
    "min_n_products = 2\n",
    "\n",
    "# we want to set min support to 7\n",
    "# but we have to express it as a percentage\n",
    "min_support = 7/len(baskets)\n",
    "\n",
    "# we have no limit on the size of association rules\n",
    "# so we set it to the longest transaction\n",
    "max_length = max([len(x) for x in baskets])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11687/11687 [00:50<00:00, 232.95it/s]\n",
      "100%|██████████| 11687/11687 [00:07<00:00, 1618.54it/s]\n",
      "100%|██████████| 11687/11687 [00:07<00:00, 1587.45it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-76-f4f4df10940a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m rule_indices, rule_supports = my_eclat.fit(min_support=min_support,\n\u001B[0;32m      8\u001B[0m                                            \u001B[0mmin_combination\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmin_n_products\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m                                            max_combination=max_length)\n\u001B[0m",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pyECLAT\\pyECLAT.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, min_support, min_combination, max_combination, separator, verbose)\u001B[0m\n\u001B[0;32m    270\u001B[0m             \u001B[0mmin_support\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    271\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 272\u001B[1;33m         \u001B[0msupport_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mECLAT\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msupport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_support\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmin_support\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    273\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    274\u001B[0m         \u001B[0mtotal\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pyECLAT\\pyECLAT.py\u001B[0m in \u001B[0;36msupport\u001B[1;34m(self, min_support)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mcolumn\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcolumn_names\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 153\u001B[1;33m                 \u001B[0mnumerator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdf_bin\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdf_bin\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    154\u001B[0m                 \u001B[0msupport\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumerator\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mtotal\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1758\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mKeyError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIndexError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1759\u001B[0m                     \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1760\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1761\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1762\u001B[0m             \u001B[1;31m# we by definition only have the 0th axis\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1268\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_getitem_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtup\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1269\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1270\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_lowerdim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1271\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mIndexingError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1272\u001B[0m             \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_lowerdim\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1417\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0msection\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1418\u001B[0m                 \u001B[1;31m# This is an elided recursive call to iloc/loc/etc'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1419\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msection\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnew_key\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1421\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mIndexingError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"not applicable\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1758\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mKeyError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIndexError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1759\u001B[0m                     \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1760\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1761\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1762\u001B[0m             \u001B[1;31m# we by definition only have the 0th axis\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1285\u001B[0m                 \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1286\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1287\u001B[1;33m             \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mretval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1288\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1289\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1948\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1949\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ndim\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1950\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Cannot index with multidimensional key\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1951\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1952\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_iterable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "from pyECLAT import ECLAT\n",
    "\n",
    "# create an instance of eclat\n",
    "my_eclat = ECLAT(data=data, verbose=True)\n",
    "\n",
    "# fit the algorithm\n",
    "rule_indices, rule_supports = my_eclat.fit(min_support=min_support,\n",
    "                                           min_combination=min_n_products,\n",
    "                                           max_combination=max_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 4\n",
    "Enough libraries tried that didn't work, let's just implement eclat ourselves.\n",
    "I based this implementation on the explanation from the lecture and [this explanation](https://www.geeksforgeeks.org/ml-eclat-algorithm/).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making tid list: 100%|██████████| 13137/13137 [00:00<00:00, 364916.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(frozenset({5614842}),\n  {0,\n   152,\n   1026,\n   1470,\n   1576,\n   1691,\n   1799,\n   1814,\n   1910,\n   2027,\n   2322,\n   2694,\n   3259,\n   4929,\n   5229,\n   5693,\n   6024,\n   6594,\n   6647,\n   6702,\n   6755,\n   6980,\n   7351,\n   8335,\n   9987,\n   10223,\n   13101}),\n (frozenset({5766379}), {0, 85, 4706, 4933, 6206, 6473, 8476, 9647, 12363}),\n (frozenset({5894239}), {1, 7278, 10877}),\n (frozenset({5861791}), {1, 3982, 7420}),\n (frozenset({5830275}), {2, 2588, 2855, 12148})]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def make_tid_dict(baskets):\n",
    "    tid_dict = dict()\n",
    "    for index, item_set in tqdm(enumerate(baskets), total=len(baskets), desc=\"Making tid list\"):\n",
    "        for item in item_set:\n",
    "            frozen_set = frozenset({item})\n",
    "            if frozen_set not in tid_dict:\n",
    "                tid_dict[frozen_set] = set()\n",
    "            tid_dict[frozen_set].add(index)\n",
    "    return tid_dict\n",
    "\n",
    "tid_dict = make_tid_dict(baskets)\n",
    "list(tid_dict.items())[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering min support: 100%|██████████| 11678/11678 [00:00<00:00, 1933107.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29100630/29100630 [00:25<00:00, 1157023.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6592056/6592056 [00:04<00:00, 1528049.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133590/133590 [00:00<00:00, 1322797.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [00:00<00:00, 1123152.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import permutations\n",
    "\n",
    "min_support = 2\n",
    "\n",
    "def combine_sets(tid_dict, min_support):\n",
    "    new_tid_dict = dict()\n",
    "    combs = list(permutations(tid_dict.items(), r=2))\n",
    "    for dict_item1, dict_item2 in tqdm(combs, total=len(combs)):\n",
    "        item_set1, tid_set1 = dict_item1\n",
    "        item_set2, tid_set2 = dict_item2\n",
    "\n",
    "        assert len(item_set1) == len(item_set2)\n",
    "        assert len(tid_set1) >= min_support and len(tid_set2) >= min_support\n",
    "\n",
    "        new_set = frozenset(item_set1 | item_set2) # Same for this union operator\n",
    "\n",
    "        # Only search for sets one size larger\n",
    "        if len(new_set) != len(item_set1)+1:\n",
    "            continue\n",
    "\n",
    "        new_set_items = tid_set1 & tid_set2 # Note: This intersection operator is new from python 3.9\n",
    "\n",
    "        if len(new_set_items) >= min_support:\n",
    "            new_tid_dict[new_set] = new_set_items\n",
    "    return new_tid_dict\n",
    "\n",
    "def filter_min_support(tid_dict, min_support):\n",
    "    items = dict()\n",
    "    for item in tqdm(tid_dict, total=len(tid_dict), desc=\"Filtering min support\"):\n",
    "        if len(tid_dict[item]) >= min_support:\n",
    "            items[item] = tid_dict[item]\n",
    "    return items\n",
    "\n",
    "items = filter_min_support(tid_dict, min_support)\n",
    "\n",
    "def mine_freq_itemsets(items, min_support):\n",
    "    new_results = items\n",
    "    freq_itemsets = items\n",
    "    i = 1\n",
    "    while new_results:\n",
    "        i += 1\n",
    "        print(f\"Mining frequent itemsets of length {i}\")\n",
    "        new_results = combine_sets(new_results, min_support)\n",
    "        freq_itemsets |= new_results\n",
    "    return freq_itemsets\n",
    "\n",
    "freq_itemsets = mine_freq_itemsets(items, min_support)\n",
    "#freq_itemsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Cool, we have quite some frequent itemsets now, let's create some rules based on this\n",
    "from more_itertools import set_partitions\n",
    "\n",
    "min_confidence = 0\n",
    "\n",
    "class Rule:\n",
    "\n",
    "    def __init__(self, x: frozenset, y: frozenset, confidence: float, sup: float, lift: float):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.sup = sup\n",
    "        self.confidence  = confidence\n",
    "        self.lift = lift\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{set(self.x)} -> {set(self.y)} ({self.confidence:.2f}, {self.sup})\"\n",
    "\n",
    "def get_rules(freq_itemsets, min_confidence):\n",
    "    rules = list()\n",
    "\n",
    "    for freq_itemset, tids in freq_itemsets.items():\n",
    "        n_freq_itemset_transactions = len(tids) # Note that the freq itemset is also #XandY occurances\n",
    "\n",
    "        # Check all possible bi partitions and see if the generated rule would match the min confidence\n",
    "        for x, y in set_partitions(freq_itemset, 2):\n",
    "            x = frozenset(x)\n",
    "            y = frozenset(y)\n",
    "\n",
    "            if x not in freq_itemsets:\n",
    "                # TODO: How come it's not possible that x is in it, but {x, y} is? This should be impossible\n",
    "                continue # x not in freq_itemset, would mean x (and thus also {x, y}) don't meet the minsup\n",
    "\n",
    "            n_x_occurances = len(freq_itemsets[x])\n",
    "            n_y_occurances = len(freq_itemsets[y])\n",
    "            confidence = n_freq_itemset_transactions / n_x_occurances\n",
    "\n",
    "            if confidence < min_confidence:\n",
    "                continue\n",
    "\n",
    "            p_xy = n_freq_itemset_transactions / len(baskets)\n",
    "            p_x = n_x_occurances / len(baskets)\n",
    "            p_y = n_y_occurances / len(baskets)\n",
    "            lift =  p_xy / (p_x*p_y)\n",
    "\n",
    "            y = frozenset(y)\n",
    "            rules.append(Rule(x=x, y=y, confidence=confidence, sup=n_freq_itemset_transactions, lift=lift))\n",
    "    return rules\n",
    "\n",
    "rules = get_rules(freq_itemsets, min_confidence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5677043} -> {5697463} (0.33, 55)\n",
      "{5814516} -> {5814517} (0.88, 49)\n",
      "{5809912} -> {5809910} (0.58, 49)\n",
      "{5809910} -> {5809911} (0.16, 47)\n",
      "{5649235} -> {5649236} (0.35, 30)\n",
      "{5886282} -> {5909810} (0.35, 30)\n",
      "{5751422} -> {5751383} (0.28, 30)\n",
      "{5886282} -> {5892179} (0.33, 28)\n",
      "{5649236} -> {5649271} (0.14, 27)\n",
      "{5886282} -> {5900651} (0.31, 26)\n"
     ]
    }
   ],
   "source": [
    "# Top 10 in terms of support\n",
    "rules.sort(key=lambda x: (x.sup, x.confidence), reverse=True)\n",
    "for rule in rules[:10]:\n",
    "    print(rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5902865} -> {5902863} (1.00, 2)\n",
      "{5801480} -> {5801481} (1.00, 2)\n",
      "{5853128} -> {5853126} (1.00, 2)\n",
      "{5919384} -> {5919382} (1.00, 2)\n",
      "{5850498} -> {5848914} (1.00, 2)\n",
      "{5840251} -> {5840213} (1.00, 2)\n",
      "{5862904} -> {5861441} (1.00, 2)\n",
      "{5853752} -> {5853751} (1.00, 2)\n",
      "{5897774} -> {5898382} (1.00, 2)\n",
      "{5857881} -> {5857882} (1.00, 2)\n"
     ]
    }
   ],
   "source": [
    "# Top 10 in terms of lift\n",
    "rules.sort(key=lambda x: (x.lift, x.sup, x.confidence), reverse=True)\n",
    "for rule in rules[:10]:\n",
    "    print(rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5814516} -> {5814517} (0.88, 49)\n",
      "{5855091} -> {5855092} (0.82, 18)\n",
      "{5739056} -> {5739055} (0.74, 17)\n",
      "{5846436} -> {5846437} (0.74, 17)\n",
      "{5816166} -> {5809910} (0.78, 14)\n",
      "{5827356} -> {5827357} (0.92, 12)\n",
      "{5707826} -> {5692527} (1.00, 9)\n",
      "{5739122} -> {5739124} (0.82, 9)\n",
      "{5787479} -> {5692527} (0.75, 9)\n",
      "{5814516, 5804820} -> {5814517} (0.89, 8)\n"
     ]
    }
   ],
   "source": [
    "filtered_rules = list(filter(lambda x: x.confidence > 0.7, rules))\n",
    "filtered_rules.sort(key=lambda x: (x.sup, x.confidence), reverse=True)\n",
    "for rule in filtered_rules[:10]:\n",
    "    print(rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5814516} -> {5814517} (0.88, 49)\n",
      "{5855091} -> {5855092} (0.82, 18)\n",
      "{5739056} -> {5739055} (0.74, 17)\n",
      "{5846436} -> {5846437} (0.74, 17)\n",
      "{5827356} -> {5827357} (0.92, 12)\n",
      "{5816166} -> {5809910} (0.78, 14)\n",
      "{5707826} -> {5692527} (1.00, 9)\n",
      "{5739122} -> {5739124} (0.82, 9)\n",
      "{5814516, 5804820} -> {5814517} (0.89, 8)\n",
      "{5787479} -> {5692527} (0.75, 9)\n"
     ]
    }
   ],
   "source": [
    "filtered_rules.sort(key=lambda x: (x.sup*x.confidence, x.sup, x.confidence), reverse=True)\n",
    "for rule in filtered_rules[:10]:\n",
    "    print(rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra information"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'cart5614842', 'cart5766379', 'purchase5614842', 'purchase5766379'},\n {'cart5861791',\n  'cart5894239',\n  'purchase5861791',\n  'purchase5894239',\n  'view5861791',\n  'view5894239'},\n {'cart5830270', 'cart5830275', 'purchase5830270', 'remove_from_cart5830275'},\n {'cart5751383',\n  'purchase5751383',\n  'view5635117',\n  'view5751383',\n  'view5809910'},\n {'cart5767496',\n  'cart5767497',\n  'cart5891498',\n  'purchase5767496',\n  'purchase5767497',\n  'purchase5891498',\n  'view5891498'}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = dataset[dataset[\"event_type\"] == \"purchase\"]\n",
    "dataset[\"action_and_product_id\"] = dataset[\"event_type\"] + dataset[\"product_id\"].astype(str)\n",
    "new_baskets = dataset.groupby(\"user_id\").action_and_product_id.apply(set).tolist()\n",
    "new_baskets[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making tid list: 100%|██████████| 13137/13137 [00:00<00:00, 114200.92it/s]\n",
      "Filtering min support: 100%|██████████| 28110/28110 [00:00<00:00, 2802383.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43158330/43158330 [00:40<00:00, 1057807.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45420860/45420860 [00:32<00:00, 1409797.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15386006/15386006 [00:11<00:00, 1340131.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2101050/2101050 [00:01<00:00, 1229379.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142506/142506 [00:00<00:00, 1104418.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4556/4556 [00:00<00:00, 1138675.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets of length 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def baskets_to_rules(baskets, min_support, min_confidence):\n",
    "    tid_dict = make_tid_dict(baskets)\n",
    "    items = filter_min_support(tid_dict, min_support)\n",
    "    freq_itemsets = mine_freq_itemsets(items, min_support)\n",
    "    rules = get_rules(freq_itemsets, min_confidence)\n",
    "    return rules\n",
    "\n",
    "rules = baskets_to_rules(new_baskets, 3, 0) # Note that I increased the min_support a lot here because computing the rules took way too long with minsup=2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'purchase5814516'} -> {'purchase5814517'} (0.90, 46)\n",
      "{'purchase5814516', 'cart5814516'} -> {'purchase5814517'} (0.90, 43)\n",
      "{'cart5814516'} -> {'purchase5814517'} (0.86, 43)\n",
      "{'cart5809911'} -> {'purchase5809910'} (0.78, 36)\n",
      "{'purchase5819894'} -> {'purchase5823667'} (0.82, 23)\n",
      "{'purchase5814516', 'purchase5814518'} -> {'purchase5814517'} (1.00, 18)\n",
      "{'purchase5814518'} -> {'purchase5814517'} (0.86, 19)\n",
      "{'purchase5855091'} -> {'purchase5855092'} (1.00, 16)\n",
      "{'cart5814516', 'purchase5814518'} -> {'purchase5814517'} (1.00, 16)\n",
      "{'purchase5855091', 'cart5855091'} -> {'purchase5855092'} (1.00, 16)\n"
     ]
    }
   ],
   "source": [
    "def get_item_nr(action_item):\n",
    "    # Returns only the item id, e.g. view1234 -> returns 1234\n",
    "    return int(''.join(char for char in action_item if char.isdigit()))\n",
    "\n",
    "def all_right_set_items_new_purchases(rule):\n",
    "    # Checks whether all items in the right set are purchases and that this item didn't appear with another action on the left side\n",
    "    x, y = rule.x, rule.y\n",
    "\n",
    "    x_itemids = set()\n",
    "    for item in x:\n",
    "        x_itemids.add(get_item_nr(item))\n",
    "\n",
    "    for item in y:\n",
    "        if not \"purchase\" in item or get_item_nr(item) in x_itemids:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "filtered_rules = list(filter(lambda x: x.confidence > 0.7, rules)) # Applying confidence afterwards and not in the baskets_to_rules function, so it's less computationally intensive to play around with it\n",
    "filtered_rules = list(filter(lambda rule: all_right_set_items_new_purchases(rule), filtered_rules))\n",
    "filtered_rules.sort(key=lambda x: (x.sup*x.confidence, x.sup, x.confidence), reverse=True)\n",
    "\n",
    "for rule in filtered_rules[:10]:\n",
    "    print(rule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}