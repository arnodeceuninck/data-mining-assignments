{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import data\n",
    "This is the (slightly modified) code from the assignment to load the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[{5614842, 5766379},\n {5861791, 5894239},\n {5830270, 5830275},\n {5635117, 5751383, 5809910},\n {5767496, 5767497, 5891498}]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"Assignment_1/dataset.csv\")\n",
    "baskets = dataset.groupby(\"user_id\").product_id.apply(set).tolist()\n",
    "baskets[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Association rule mining algorithm\n",
    "> Implement an association rule mining algorithm, or use an existing online implementation.\n",
    "Show that you understand the method by describing its function (without using code) in your\n",
    "report. Make sure you are able to get the confidence and support of any found association\n",
    "rules.\n",
    "\n",
    "> Run the association rule mining algorithm on the given dataset. At this point, use only the\n",
    "user id and product id columns. What are the top 10 association rules in terms of support\n",
    "your method finds? Also include the confidence of these rules. What can you say about the\n",
    "number of items in these rules?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 1\n",
    "I started with the apyori implementation, but this also allowed empty baskets, which causes errors in the inspect function. You can just skip to my own implementation, which you can find under the \"Method 4\" subtitle.\n",
    "Using code from [this article](https://www.section.io/engineering-education/apriori-algorithm-in-python/), with the apriori algorithm from [apyori](https://pypi.org/project/apyori/)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "# support: measures the number of times a particular item or combination of items occur in a dataset\n",
    "# confidence: measures how likely the customer is to consume item2 given they have consumed item1\n",
    "# lift: a metric that determines the strength of association between the best rules, confidence/support\n",
    "# TODO: define own min_upport, min_confidence and min_lift\n",
    "rule = apriori(transactions=baskets, min_support=0.003, min_confidence=0.2, min_lift=3, min_length=2, max_length=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "   Left_Hand_Side  Right_Hand_Side   Support  Confidence        Lift\n0         5677043          5697463  0.004187    0.329341   57.687425\n2         5809912          5809910  0.003730    0.583333   25.459302\n3         5814516          5814517  0.003730    0.875000  201.664474\n1         5809911          5809910  0.003578    0.746032   32.560196",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Left_Hand_Side</th>\n      <th>Right_Hand_Side</th>\n      <th>Support</th>\n      <th>Confidence</th>\n      <th>Lift</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5677043</td>\n      <td>5697463</td>\n      <td>0.004187</td>\n      <td>0.329341</td>\n      <td>57.687425</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5809912</td>\n      <td>5809910</td>\n      <td>0.003730</td>\n      <td>0.583333</td>\n      <td>25.459302</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5814516</td>\n      <td>5814517</td>\n      <td>0.003730</td>\n      <td>0.875000</td>\n      <td>201.664474</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5809911</td>\n      <td>5809910</td>\n      <td>0.003578</td>\n      <td>0.746032</td>\n      <td>32.560196</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list(rule)\n",
    "\n",
    "# putting output into a pandas dataframe\n",
    "def inspect(output):\n",
    "    for result in output:\n",
    "        try:\n",
    "            tuple(result[2][0][0])[0]\n",
    "        except Exception as e:\n",
    "            print(result)\n",
    "            raise e\n",
    "    lhs = [tuple(result[2][0][0])[0] for result in output]\n",
    "    rhs = [tuple(result[2][0][1])[0] for result in output]\n",
    "    support = [result[1] for result in output]\n",
    "    confidence = [result[2][0][2] for result in output]\n",
    "    lift = [result[2][0][3] for result in output]\n",
    "    return list(zip(lhs, rhs, support, confidence, lift))\n",
    "\n",
    "output_DataFrame = pd.DataFrame(inspect(results),\n",
    "                                columns=['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
    "\n",
    "output_DataFrame.nlargest(n=10, columns='Support')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 2\n",
    "Using code from [this site](https://towardsdatascience.com/apriori-association-rule-mining-explanation-and-python-implementation-290b42afdfc6), which uses the [apriori_python library](https://pypi.org/project/apriori-python/). This method is also very slow, so trying eclat insted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5614842, 5766379], [5894239, 5861791], [5830275, 5830270], [5635117, 5809910, 5751383], [5767496, 5767497, 5891498]]\n",
      "{1: {frozenset({5809910}), frozenset({5649236}), frozenset({5677043}), frozenset({5790689})}}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from apriori_python import apriori\n",
    "freqItemSet, rules = apriori(baskets, minSup=0.01, minConf=0.001)\n",
    "print(freqItemSet)\n",
    "print(rules)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 3\n",
    "Let's try running eclat on it. To do this, I'll use code from [this site](https://towardsdatascience.com/the-eclat-algorithm-8ae3276d2d17), which makes use of [pyECLAT](https://pypi.org/project/pyECLAT/). This method also gives an error.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "         0          1          2   3   4   5   6   7   8   9\n0  5614842  5766379.0        NaN NaN NaN NaN NaN NaN NaN NaN\n1  5894239  5861791.0        NaN NaN NaN NaN NaN NaN NaN NaN\n2  5830275  5830270.0        NaN NaN NaN NaN NaN NaN NaN NaN\n3  5635117  5809910.0  5751383.0 NaN NaN NaN NaN NaN NaN NaN\n4  5767496  5767497.0  5891498.0 NaN NaN NaN NaN NaN NaN NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5614842</td>\n      <td>5766379.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5894239</td>\n      <td>5861791.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5830275</td>\n      <td>5830270.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5635117</td>\n      <td>5809910.0</td>\n      <td>5751383.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5767496</td>\n      <td>5767497.0</td>\n      <td>5891498.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(baskets)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# we are looking for itemSETS\n",
    "# we do not want to have any individual products returned\n",
    "min_n_products = 2\n",
    "\n",
    "# we want to set min support to 7\n",
    "# but we have to express it as a percentage\n",
    "min_support = 7/len(baskets)\n",
    "\n",
    "# we have no limit on the size of association rules\n",
    "# so we set it to the longest transaction\n",
    "max_length = max([len(x) for x in baskets])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11687/11687 [00:50<00:00, 232.95it/s]\n",
      "100%|██████████| 11687/11687 [00:07<00:00, 1618.54it/s]\n",
      "100%|██████████| 11687/11687 [00:07<00:00, 1587.45it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-76-f4f4df10940a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m rule_indices, rule_supports = my_eclat.fit(min_support=min_support,\n\u001B[0;32m      8\u001B[0m                                            \u001B[0mmin_combination\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmin_n_products\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m                                            max_combination=max_length)\n\u001B[0m",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pyECLAT\\pyECLAT.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, min_support, min_combination, max_combination, separator, verbose)\u001B[0m\n\u001B[0;32m    270\u001B[0m             \u001B[0mmin_support\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    271\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 272\u001B[1;33m         \u001B[0msupport_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mECLAT\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msupport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_support\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmin_support\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    273\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    274\u001B[0m         \u001B[0mtotal\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pyECLAT\\pyECLAT.py\u001B[0m in \u001B[0;36msupport\u001B[1;34m(self, min_support)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mcolumn\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcolumn_names\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 153\u001B[1;33m                 \u001B[0mnumerator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdf_bin\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdf_bin\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    154\u001B[0m                 \u001B[0msupport\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumerator\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mtotal\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1758\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mKeyError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIndexError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1759\u001B[0m                     \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1760\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1761\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1762\u001B[0m             \u001B[1;31m# we by definition only have the 0th axis\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1268\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_getitem_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtup\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1269\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1270\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_lowerdim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1271\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mIndexingError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1272\u001B[0m             \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_lowerdim\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1417\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0msection\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1418\u001B[0m                 \u001B[1;31m# This is an elided recursive call to iloc/loc/etc'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1419\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msection\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnew_key\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1421\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mIndexingError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"not applicable\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1758\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mKeyError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIndexError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1759\u001B[0m                     \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1760\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1761\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1762\u001B[0m             \u001B[1;31m# we by definition only have the 0th axis\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1285\u001B[0m                 \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1286\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1287\u001B[1;33m             \u001B[0mretval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mretval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1288\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1289\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\documents\\reinforcement-learning-labs\\rlenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1948\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1949\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ndim\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1950\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Cannot index with multidimensional key\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1951\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1952\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_iterable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "from pyECLAT import ECLAT\n",
    "\n",
    "# create an instance of eclat\n",
    "my_eclat = ECLAT(data=data, verbose=True)\n",
    "\n",
    "# fit the algorithm\n",
    "rule_indices, rule_supports = my_eclat.fit(min_support=min_support,\n",
    "                                           min_combination=min_n_products,\n",
    "                                           max_combination=max_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 4\n",
    "Enough libraries tried that didn't work, let's just implement eclat ourselves.\n",
    "TODO: Maybe this site can help: https://www.geeksforgeeks.org/ml-eclat-algorithm/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    ">If you were asked to give the 10 most interesting rules, which 10 would you give and why?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> A lot of information from the dataset was omitted in the current association rules, such as\n",
    "the event types, which describe whether an item was viewed, purchased, added or removed\n",
    "from the cart and the prices of items. Find a way to incorporate the additional information\n",
    "provided into your association rules. Describe what you have added in your report."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> After adding additional information, which rules would you deem most interesting now, and\n",
    "why?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}